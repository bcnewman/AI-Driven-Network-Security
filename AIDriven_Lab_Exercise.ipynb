{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyP+0d8W2d9MRrlLI0229AoG",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/bcnewman/AI-Driven-Network-Security/blob/main/AIDriven_Lab_Exercise.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G1NkW06aSIb1"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Set random seed for reproducibility\n",
        "np.random.seed(42)\n",
        "\n",
        "# Generate sample data\n",
        "n_samples = 1000\n",
        "data = {\n",
        "    'duration': np.random.randint(0, 3600, n_samples),  # Connection duration in seconds\n",
        "    'protocol': np.random.choice(['TCP', 'UDP', 'ICMP'], n_samples),\n",
        "    'src_bytes': np.random.randint(0, 1000000, n_samples),  # Bytes sent by source\n",
        "    'dst_bytes': np.random.randint(0, 1000000, n_samples),  # Bytes sent by destination\n",
        "    'flag': np.random.choice(['S0', 'S1', 'SF', 'REJ'], n_samples),  # Connection status flag\n",
        "    'land': np.random.choice([0, 1], n_samples, p=[0.99, 0.01]),  # 1 if connection is to/from the same host/port, 0 otherwise\n",
        "    'wrong_fragment': np.random.randint(0, 3, n_samples),  # Number of wrong fragments\n",
        "    'urgent': np.random.randint(0, 3, n_samples),  # Number of urgent packets\n",
        "}\n",
        "\n",
        "# Create DataFrame\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "# Add a target variable (0 for normal, 1 for intrusion)\n",
        "df['intrusion'] = np.random.choice([0, 1], n_samples, p=[0.8, 0.2])\n",
        "\n",
        "# Adjust some features to correlate with intrusions\n",
        "df.loc[df['intrusion'] == 1, 'duration'] += np.random.randint(1800, 3600, sum(df['intrusion'] == 1))\n",
        "df.loc[df['intrusion'] == 1, 'src_bytes'] += np.random.randint(500000, 1000000, sum(df['intrusion'] == 1))\n",
        "\n",
        "# Save to CSV\n",
        "df.to_csv('simplified_network_data.csv', index=False)\n",
        "\n",
        "print(\"Dataset created and saved as 'simplified_network_data.csv'\")\n",
        "print(df.head())\n",
        "print(\"\\nDataset shape:\", df.shape)\n",
        "print(\"\\nIntrusion distribution:\\n\", df['intrusion'].value_counts(normalize=True))"
      ],
      "metadata": {
        "id": "Pe_dVoD5SLpt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Load the data\n",
        "print(\"Loading the dataset...\")\n",
        "df = pd.read_csv('simplified_network_data.csv')\n",
        "\n",
        "# Display basic information about the dataset\n",
        "print(\"\\nDataset Overview:\")\n",
        "print(df.info())\n",
        "\n",
        "# Show the first few rows of the data\n",
        "print(\"\\nFirst few rows of the dataset:\")\n",
        "print(df.head())\n",
        "\n",
        "# Describe the numerical features\n",
        "print(\"\\nSummary statistics of numerical features:\")\n",
        "print(df.describe())\n",
        "\n",
        "# Display the distribution of the 'protocol' feature\n",
        "print(\"\\nDistribution of protocols:\")\n",
        "print(df['protocol'].value_counts(normalize=True))\n",
        "\n",
        "# Visualize the distribution of normal vs. intrusion connections\n",
        "plt.figure(figsize=(8, 6))\n",
        "df['intrusion'].value_counts().plot(kind='bar')\n",
        "plt.title('Distribution of Normal vs. Intrusion Connections')\n",
        "plt.xlabel('Connection Type (0: Normal, 1: Intrusion)')\n",
        "plt.ylabel('Count')\n",
        "plt.show()\n",
        "\n",
        "# Correlation between numerical features\n",
        "correlation_matrix = df[['duration', 'src_bytes', 'dst_bytes', 'wrong_fragment', 'urgent', 'intrusion']].corr()\n",
        "print(\"\\nCorrelation matrix:\")\n",
        "print(correlation_matrix)\n",
        "\n",
        "# Script to explain the features\n",
        "print(\"\\nExplanation of key features:\")\n",
        "print(\"1. duration: The length of the connection in seconds.\")\n",
        "print(\"2. protocol: The type of protocol used (e.g., TCP, UDP, ICMP).\")\n",
        "print(\"3. src_bytes: The number of data bytes transferred from source to destination.\")\n",
        "print(\"4. dst_bytes: The number of data bytes transferred from destination to source.\")\n",
        "print(\"5. flag: Indicates the status of the connection (e.g., SF for normal connection, S0 for connection attempt rejected).\")\n",
        "print(\"6. land: Binary feature. 1 if connection is from/to the same host/port; 0 otherwise.\")\n",
        "print(\"7. wrong_fragment: Number of wrong fragments in the connection.\")\n",
        "print(\"8. urgent: Number of urgent packets.\")\n",
        "print(\"9. intrusion: Our target variable. 0 for normal connection, 1 for potential intrusion.\")"
      ],
      "metadata": {
        "id": "cTzXCZS4TQZ9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Load the data\n",
        "print(\"Loading the dataset...\")\n",
        "df = pd.read_csv('simplified_network_data.csv')\n",
        "\n",
        "# Separate features and target variable\n",
        "X = df.drop('intrusion', axis=1)\n",
        "y = df['intrusion']\n",
        "\n",
        "# Identify numerical and categorical columns\n",
        "numerical_features = ['duration', 'src_bytes', 'dst_bytes', 'wrong_fragment', 'urgent']\n",
        "categorical_features = ['protocol', 'flag', 'land']\n",
        "\n",
        "# Create preprocessing steps for numerical and categorical data\n",
        "preprocessor = ColumnTransformer(\n",
        "    transformers=[\n",
        "        ('num', StandardScaler(), numerical_features),\n",
        "        ('cat', OneHotEncoder(drop='first', sparse_output=False), categorical_features)\n",
        "    ])\n",
        "\n",
        "# Fit the preprocessor to the data and transform\n",
        "X_preprocessed = preprocessor.fit_transform(X)\n",
        "\n",
        "# Get feature names after preprocessing\n",
        "feature_names = (numerical_features +\n",
        "                 preprocessor.named_transformers_['cat'].get_feature_names_out(categorical_features).tolist())\n",
        "\n",
        "# Create a new dataframe with preprocessed data\n",
        "X_preprocessed_df = pd.DataFrame(X_preprocessed, columns=feature_names)\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_preprocessed, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Save preprocessed data and target variable\n",
        "print(\"Saving preprocessed data...\")\n",
        "X_preprocessed_df.to_csv('preprocessed_features.csv', index=False)\n",
        "pd.DataFrame(y, columns=['intrusion']).to_csv('target_variable.csv', index=False)\n",
        "\n",
        "# Save training and testing sets\n",
        "pd.DataFrame(X_train, columns=feature_names).to_csv('X_train.csv', index=False)\n",
        "pd.DataFrame(X_test, columns=feature_names).to_csv('X_test.csv', index=False)\n",
        "pd.DataFrame(y_train, columns=['intrusion']).to_csv('y_train.csv', index=False)\n",
        "pd.DataFrame(y_test, columns=['intrusion']).to_csv('y_test.csv', index=False)\n",
        "\n",
        "print(\"\\nShape of training set:\", X_train.shape)\n",
        "print(\"Shape of testing set:\", X_test.shape)\n",
        "\n",
        "# Display the first few rows of the preprocessed data\n",
        "print(\"\\nFirst few rows of preprocessed data:\")\n",
        "print(X_preprocessed_df.head())\n",
        "\n",
        "# Display summary statistics of preprocessed numerical features\n",
        "print(\"\\nSummary statistics of preprocessed numerical features:\")\n",
        "print(X_preprocessed_df[numerical_features].describe())\n",
        "\n",
        "print(\"\\nPreprocessed data and splits have been saved as CSV files.\")"
      ],
      "metadata": {
        "id": "bvTMhLH9UBGr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, confusion_matrix\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Load the preprocessed data\n",
        "print(\"Loading preprocessed data...\")\n",
        "X_train = pd.read_csv('X_train.csv')\n",
        "X_test = pd.read_csv('X_test.csv')\n",
        "y_train = pd.read_csv('y_train.csv')['intrusion']\n",
        "y_test = pd.read_csv('y_test.csv')['intrusion']\n",
        "\n",
        "# Initialize the Random Forest Classifier\n",
        "rf_classifier = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "\n",
        "# Train the model\n",
        "print(\"Training the Random Forest Classifier...\")\n",
        "rf_classifier.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions on the test set\n",
        "y_pred = rf_classifier.predict(X_test)\n",
        "\n",
        "# Calculate performance metrics\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "precision = precision_score(y_test, y_pred)\n",
        "recall = recall_score(y_test, y_pred)\n",
        "\n",
        "print(f\"\\nModel Performance:\")\n",
        "print(f\"Accuracy: {accuracy:.4f}\")\n",
        "print(f\"Precision: {precision:.4f}\")\n",
        "print(f\"Recall: {recall:.4f}\")\n",
        "\n",
        "# Generate and display confusion matrix\n",
        "conf_matrix = confusion_matrix(y_test, y_pred)\n",
        "plt.figure(figsize=(10,7))\n",
        "sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues')\n",
        "plt.title('Confusion Matrix')\n",
        "plt.ylabel('Actual')\n",
        "plt.xlabel('Predicted')\n",
        "plt.show()\n",
        "\n",
        "# Display feature importances\n",
        "feature_importance = pd.DataFrame({\n",
        "    'feature': X_train.columns,\n",
        "    'importance': rf_classifier.feature_importances_\n",
        "}).sort_values('importance', ascending=False)\n",
        "\n",
        "plt.figure(figsize=(10,7))\n",
        "sns.barplot(x='importance', y='feature', data=feature_importance.head(10))\n",
        "plt.title('Top 10 Most Important Features')\n",
        "plt.show()\n",
        "\n",
        "print(\"\\nTop 10 Most Important Features:\")\n",
        "print(feature_importance.head(10))"
      ],
      "metadata": {
        "id": "m-HTl_AaUpak"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, confusion_matrix, roc_curve, auc\n",
        "\n",
        "# Load the preprocessed data\n",
        "print(\"Loading preprocessed data...\")\n",
        "X_train = pd.read_csv('X_train.csv')\n",
        "X_test = pd.read_csv('X_test.csv')\n",
        "y_train = pd.read_csv('y_train.csv')['intrusion']\n",
        "y_test = pd.read_csv('y_test.csv')['intrusion']\n",
        "\n",
        "# Initialize and train the Random Forest Classifier\n",
        "print(\"Training the Random Forest Classifier...\")\n",
        "rf_classifier = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "rf_classifier.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions on the test set\n",
        "y_pred = rf_classifier.predict(X_test)\n",
        "y_pred_proba = rf_classifier.predict_proba(X_test)[:, 1]\n",
        "\n",
        "# Calculate performance metrics\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "precision = precision_score(y_test, y_pred)\n",
        "recall = recall_score(y_test, y_pred)\n",
        "\n",
        "print(f\"\\nModel Performance:\")\n",
        "print(f\"Accuracy: {accuracy:.4f}\")\n",
        "print(f\"Precision: {precision:.4f}\")\n",
        "print(f\"Recall: {recall:.4f}\")\n",
        "\n",
        "# Generate and display confusion matrix\n",
        "conf_matrix = confusion_matrix(y_test, y_pred)\n",
        "plt.figure(figsize=(10,7))\n",
        "sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues')\n",
        "plt.title('Confusion Matrix')\n",
        "plt.ylabel('Actual')\n",
        "plt.xlabel('Predicted')\n",
        "plt.show()\n",
        "\n",
        "# Display feature importances\n",
        "feature_importance = pd.DataFrame({\n",
        "    'feature': X_train.columns,\n",
        "    'importance': rf_classifier.feature_importances_\n",
        "}).sort_values('importance', ascending=False)\n",
        "\n",
        "plt.figure(figsize=(10,7))\n",
        "sns.barplot(x='importance', y='feature', data=feature_importance.head(10))\n",
        "plt.title('Top 10 Most Important Features')\n",
        "plt.show()\n",
        "\n",
        "print(\"\\nTop 10 Most Important Features:\")\n",
        "print(feature_importance.head(10))\n",
        "\n",
        "# Function to get prediction and feature importances for a single instance\n",
        "def predict_single_instance(instance):\n",
        "    prediction = rf_classifier.predict(instance.reshape(1, -1))[0]\n",
        "    probabilities = rf_classifier.predict_proba(instance.reshape(1, -1))[0]\n",
        "    return prediction, probabilities\n",
        "\n",
        "# Test the model on a few specific examples\n",
        "print(\"\\nTesting the model on specific examples:\")\n",
        "for i in range(5):  # Test 5 random instances\n",
        "    instance = X_test.iloc[i].values\n",
        "    prediction, probabilities = predict_single_instance(instance)\n",
        "    print(f\"\\nInstance {i+1}:\")\n",
        "    print(f\"Predicted class: {'Intrusion' if prediction == 1 else 'Normal'}\")\n",
        "    print(f\"Probability of being an intrusion: {probabilities[1]:.4f}\")\n",
        "\n",
        "# Visualize decision boundary (for 2 most important features)\n",
        "top_features = feature_importance['feature'].head(2).tolist()\n",
        "X_top2 = X_test[top_features]\n",
        "\n",
        "plt.figure(figsize=(10, 8))\n",
        "scatter = plt.scatter(X_top2.iloc[:, 0], X_top2.iloc[:, 1], c=y_pred_proba, cmap='coolwarm')\n",
        "plt.colorbar(scatter)\n",
        "plt.xlabel(top_features[0])\n",
        "plt.ylabel(top_features[1])\n",
        "plt.title('Decision Boundary Visualization')\n",
        "plt.show()\n",
        "\n",
        "# ROC Curve\n",
        "fpr, tpr, _ = roc_curve(y_test, y_pred_proba)\n",
        "roc_auc = auc(fpr, tpr)\n",
        "\n",
        "plt.figure(figsize=(10, 8))\n",
        "plt.plot(fpr, tpr, color='darkorange', lw=2, label=f'ROC curve (AUC = {roc_auc:.2f})')\n",
        "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
        "plt.xlim([0.0, 1.0])\n",
        "plt.ylim([0.0, 1.05])\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title('Receiver Operating Characteristic (ROC) Curve')\n",
        "plt.legend(loc=\"lower right\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Q1lv4fHvXCcs"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}